{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95605dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === SETTINGS ===\n",
    "model_name = \"EC-Earth3\"\n",
    "\n",
    "# Base CMIP6 path for this model\n",
    "data_dir = Path(f\"/dmidata/projects/nckf/cmip6/historical/{model_name}/\")\n",
    "\n",
    "# Output paths (your working directory)\n",
    "output_dir = Path(\"/data/users/frekle/AMOC_analysis/results/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_csv = output_dir / f\"AMOC_trends_{model_name}.csv\"\n",
    "plot_dir = output_dir / f\"plots_AMOC_{model_name}\"\n",
    "plot_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Variable and analysis parameters\n",
    "var_name = \"msftyz\"\n",
    "basin_index = 1        # Atlantic basin\n",
    "depth_min = 500.0      # only consider depths > 500 m\n",
    "target_lat = 26.0      # standard AMOC latitude\n",
    "start_year, end_year = 1900, 2005\n",
    "\n",
    "# === HELPER FUNCTIONS ===\n",
    "def load_amoc_timeseries(file_path):\n",
    "    \"\"\"Load AMOC strength time series (Atlantic, max below 500 m at 26¬∞N).\"\"\"\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    da = ds[var_name]\n",
    "\n",
    "    # --- Select Atlantic basin (basin=1) ---\n",
    "    if \"basin\" in da.dims:\n",
    "        da = da.sel(basin=basin_index)\n",
    "\n",
    "    # --- Select latitude closest to 26¬∞N and depth > 500 m ---\n",
    "    da_sel = da.sel(rlat=target_lat, method=\"nearest\").sel(lev=slice(depth_min, None))\n",
    "\n",
    "    # --- Take maximum overturning strength below 500 m ---\n",
    "    amoc_strength = da_sel.max(dim=\"lev\")\n",
    "\n",
    "    # --- Convert to annual mean and subset 1900‚Äì2005 ---\n",
    "    amoc_annual = amoc_strength.resample(time=\"Y\").mean()\n",
    "    amoc_annual = amoc_annual.sel(time=slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\"))\n",
    "\n",
    "    return amoc_annual\n",
    "\n",
    "def compute_trend(amoc_annual):\n",
    "    \"\"\"Compute linear trend in Sv/century and return slope and fit line.\"\"\"\n",
    "    years = amoc_annual[\"time\"].dt.year.values\n",
    "    values = amoc_annual.values\n",
    "    mask = np.isfinite(values)\n",
    "    years, values = years[mask], values[mask]\n",
    "    slope, intercept, r, p, stderr = linregress(years, values)\n",
    "    slope_sv_century = slope * 100 / 1e9  # kg/s ‚Üí Sv/century\n",
    "    fit = intercept + slope * years\n",
    "    return slope_sv_century, years, values, fit\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "results = []\n",
    "\n",
    "# Find all msftyz files inside any realization folder\n",
    "nc_files = sorted(data_dir.rglob(\"Omon/msftyz/*.nc\"))\n",
    "\n",
    "if not nc_files:\n",
    "    print(f\"‚ö†Ô∏è No files found for {model_name} in {data_dir}\")\n",
    "else:\n",
    "    for nc_file in nc_files:\n",
    "        try:\n",
    "            print(f\"Processing: {nc_file}\")\n",
    "            realization = nc_file.name.split(\"_\")[4]  # e.g. 'r1i1p1f1'\n",
    "            amoc_annual = load_amoc_timeseries(nc_file)\n",
    "            trend, years, values, fit = compute_trend(amoc_annual)\n",
    "            group = \"AMOC-\" if trend < 0 else \"AMOC+\"\n",
    "            results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Member\": realization,\n",
    "                \"AMOC_trend_Sv_per_century\": trend,\n",
    "                \"Group\": group\n",
    "            })\n",
    "            print(f\" ‚Üí {realization}: {trend:.2f} Sv/century ({group})\")\n",
    "\n",
    "            # --- Plot AMOC time series ---\n",
    "            plt.figure(figsize=(7, 4))\n",
    "            plt.plot(years, values / 1e9, label=\"AMOC strength\", lw=1.5)\n",
    "            plt.plot(years, fit / 1e9, \"--\", color=\"red\", label=\"Linear trend\")\n",
    "            plt.title(f\"{model_name} {realization} | Atlantic basin (basin={basin_index})\\n\"\n",
    "                      f\"AMOC (max below 500m, {target_lat}¬∞N)\\nTrend = {trend:.2f} Sv/century\")\n",
    "            plt.xlabel(\"Year\")\n",
    "            plt.ylabel(\"AMOC Strength [Sv]\")\n",
    "            plt.grid(alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_dir / f\"{model_name}_{realization}_AMOC_timeseries.png\", dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping {nc_file.name}: {e}\")\n",
    "\n",
    "# === SAVE RESULTS ===\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Saved results to {output_csv}\")\n",
    "    print(df)\n",
    "\n",
    "    # --- Ensemble summary ---\n",
    "    mean_trend = df[\"AMOC_trend_Sv_per_century\"].mean()\n",
    "    std_trend = df[\"AMOC_trend_Sv_per_century\"].std()\n",
    "    n_members = len(df)\n",
    "    print(f\"\\nüìä Ensemble summary for {model_name}:\")\n",
    "    print(f\" ‚Üí Members analyzed: {n_members}\")\n",
    "    print(f\" ‚Üí Mean AMOC trend: {mean_trend:.2f} ¬± {std_trend:.2f} Sv/century\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved {n_members} plots to {plot_dir}/\")\n",
    "else:\n",
    "    print(\"‚ùå No valid results were generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fe402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing only: ['r1i1p1f1']\n",
      "\n",
      "Processing member: r1i1p1f1\n",
      "  ‚úì SST: trend = 0.917 ¬∞C/century\n",
      "  ‚úì SSS: trend = 0.624 psu/century\n",
      "\n",
      "‚úÖ Saved trends table: /data/users/frekle/EOF/AMOC_analysis/results/FPI_original/FPI_trends_EC-Earth3.csv\n",
      "       Model    Member Variable  FPI_trend_SST_per_century  \\\n",
      "0  EC-Earth3  r1i1p1f1      SST                   0.916833   \n",
      "1  EC-Earth3  r1i1p1f1      SSS                        NaN   \n",
      "\n",
      "   FPI_trend_SSS_per_century  \n",
      "0                        NaN  \n",
      "1                    0.62352  \n"
     ]
    }
   ],
   "source": [
    "# FPI analysis script\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# === SETTINGS ===\n",
    "model_name = \"EC-Earth3\"\n",
    "base_path = Path(f\"/dmidata/projects/nckf/cmip6/historical/{model_name}/\")\n",
    "output_dir = Path(\"/data/users/frekle/AMOC_analysis/results/FPI_original_test/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Regions from Li & Liu (2025)\n",
    "regions = {\n",
    "    \"subpolar\": {\"lat\": (46, 58), \"lon\": (-49, -21)},\n",
    "    \"gulfstream\": {\"lat\": (41, 45), \"lon\": (-66, -40)},\n",
    "}\n",
    "\n",
    "start_year, end_year = 1900, 2005\n",
    "\n",
    "# --- helper: discover coordinate names\n",
    "def get_lat_lon_names(da):\n",
    "    for lat_name in [\"lat\", \"latitude\", \"y\"]:\n",
    "        if lat_name in da.dims or lat_name in da.coords:\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"Could not find a latitude coordinate name.\")\n",
    "\n",
    "    for lon_name in [\"lon\", \"longitude\", \"x\"]:\n",
    "        if lon_name in da.dims or lon_name in da.coords:\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"Could not find a longitude coordinate name.\")\n",
    "\n",
    "    return lat_name, lon_name\n",
    "\n",
    "# --- helper: region mean with cosine-lat weighting (0‚Äì360 or -180‚Äì180)\n",
    "def select_region_mean(da, lat, lon):\n",
    "    \"\"\"\n",
    "    Return area-weighted mean over a geographic box for both 1D and 2D lat/lon.\n",
    "    Uses cos(lat) weights. Handles 0‚Äì360 and -180‚Äì180 longitudes, and wrap-around boxes.\n",
    "    \"\"\"\n",
    "    lat_name, lon_name = get_lat_lon_names(da)\n",
    "\n",
    "    # Coordinates\n",
    "    LAT = da[lat_name]\n",
    "    LON = da[lon_name]\n",
    "\n",
    "    # Normalize longitudes to dataset convention\n",
    "    lon_min, lon_max = lon\n",
    "    if LON.max() > 180:   # dataset uses 0..360\n",
    "        lon_min = lon_min % 360\n",
    "        lon_max = lon_max % 360\n",
    "\n",
    "    # Build region mask (works for 1D or 2D lat/lon)\n",
    "    if LON.ndim == 1 and LAT.ndim == 1:\n",
    "        # 1D case: build index masks then slice\n",
    "        lat_mask = (LAT >= lat[0]) & (LAT <= lat[1])\n",
    "\n",
    "        if lon_min <= lon_max:\n",
    "            lon_mask = (LON >= lon_min) & (LON <= lon_max)\n",
    "        else:\n",
    "            # region crosses the dateline in 0..360 convention\n",
    "            lon_mask = (LON >= lon_min) | (LON <= lon_max)\n",
    "\n",
    "        sub = da.sel({lat_name: LAT[lat_mask], lon_name: LON[lon_mask]})\n",
    "\n",
    "        # weights: cos(lat) expanded to 2D to match sub\n",
    "        w_lat = xr.ufuncs.cos(np.deg2rad(sub[lat_name]))\n",
    "        W = w_lat.broadcast_like(sub)\n",
    "\n",
    "    else:\n",
    "        # 2D/curvilinear case: build boolean mask directly on coordinates\n",
    "        if lon_min <= lon_max:\n",
    "            lon_ok = (LON >= lon_min) & (LON <= lon_max)\n",
    "        else:\n",
    "            lon_ok = (LON >= lon_min) | (LON <= lon_max)\n",
    "        lat_ok = (LAT >= lat[0]) & (LAT <= lat[1])\n",
    "        mask = lon_ok & lat_ok\n",
    "\n",
    "        sub = da.where(mask)\n",
    "        W = xr.ufuncs.cos(np.deg2rad(LAT)).where(mask)\n",
    "\n",
    "    # Apply mask to weights where data is missing\n",
    "    W = W.where(np.isfinite(sub))\n",
    "\n",
    "    # Spatial dims = all non-time dims present in sub\n",
    "    spatial_dims = [d for d in sub.dims if d != \"time\"]\n",
    "\n",
    "    # Weighted mean over space (keep time)\n",
    "    num = (sub * W).sum(dim=spatial_dims, skipna=True)\n",
    "    den = W.sum(dim=spatial_dims, skipna=True)\n",
    "    return num / den\n",
    "\n",
    "\n",
    "# --- helper: load & merge all monthly files for one realization\n",
    "def open_member_mfds(var_name, member):\n",
    "    # e.g.: /.../r1i1p1f1/Omon/tos/*.nc\n",
    "    files_dir = base_path / member / \"Omon\" / var_name\n",
    "    files = sorted(files_dir.glob(\"*.nc\"))   # FIXED: give a pattern\n",
    "    if not files:\n",
    "        return None\n",
    "    # Let xarray align by coords; you can add chunks={} if desired\n",
    "    ds = xr.open_mfdataset(files, combine=\"by_coords\")\n",
    "    return ds\n",
    "\n",
    "# --- compute FPI time series and trend for a given var and member\n",
    "def compute_FPI_for_member(var_name, pretty_name, units, member):\n",
    "    ds = open_member_mfds(var_name, member)\n",
    "    if ds is None:\n",
    "        return None\n",
    "\n",
    "    da = ds[var_name]\n",
    "\n",
    "    # Ensure latitude is increasing if it's a dimension\n",
    "    lat_name, lon_name = get_lat_lon_names(da)\n",
    "    if lat_name in da.dims:\n",
    "        da = da.sortby(lat_name)\n",
    "\n",
    "    # subset in time & annual mean\n",
    "    da = da.sel(time=slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\"))\n",
    "    if da.time.size == 0:\n",
    "        return None\n",
    "\n",
    "    da_ann = da.resample(time=\"YE\").mean()  # 'YE' avoids FutureWarning\n",
    "\n",
    "    # regional means\n",
    "    subpolar = select_region_mean(da_ann, **regions[\"subpolar\"])\n",
    "    gulfstream = select_region_mean(da_ann, **regions[\"gulfstream\"])\n",
    "\n",
    "    fpi = (subpolar - gulfstream).rename(\"FPI\")\n",
    "\n",
    "    # linear trend (per century)\n",
    "    years = fpi[\"time\"].dt.year.values\n",
    "    vals = fpi.values\n",
    "    mask = np.isfinite(vals)\n",
    "    years, vals = years[mask], vals[mask]\n",
    "    slope, intercept, r, p, stderr = linregress(years, vals)\n",
    "    trend_century = slope * 100\n",
    "\n",
    "    return fpi, trend_century\n",
    "\n",
    "# --- find all realizations available (e.g. r1i1p1f1, r131i1p1f1, etc.)\n",
    "def list_realizations():\n",
    "    mems = []\n",
    "    for p in base_path.iterdir():\n",
    "        if p.is_dir() and re.match(r\"r\\d+i\\d+p\\d+f\\d+$\", p.name):\n",
    "            mems.append(p.name)\n",
    "    return sorted(mems)\n",
    "\n",
    "# === MAIN ===\n",
    "rows = []\n",
    "members = list_realizations()\n",
    "\n",
    "# --- TEST ON ONE MEMBER ONLY ---\n",
    "test_member = \"r1i1p1f1\"   # change if you want a different one\n",
    "members = [m for m in members if m == test_member]\n",
    "print(f\"Testing only: {members}\")\n",
    "\n",
    "if not members:\n",
    "    print(f\"‚ö†Ô∏è No realization folders found under {base_path}\")\n",
    "\n",
    "for member in members:\n",
    "    print(f\"\\nProcessing member: {member}\")\n",
    "\n",
    "    for var_name, pretty_name, units in [(\"tos\", \"SST\", \"¬∞C\"), (\"sos\", \"SSS\", \"psu\")]:\n",
    "        try:\n",
    "            result = compute_FPI_for_member(var_name, pretty_name, units, member)\n",
    "            if result is None:\n",
    "                print(f\"  ‚ö†Ô∏è {pretty_name}: no data/time for {member}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            fpi, trend = result\n",
    "            rows.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Member\": member,\n",
    "                \"Variable\": pretty_name,\n",
    "                f\"FPI_trend_{pretty_name}_per_century\": trend\n",
    "            })\n",
    "\n",
    "            # plot\n",
    "            plt.figure(figsize=(7, 4))\n",
    "            plt.plot(fpi[\"time\"].dt.year, fpi, label=f\"{pretty_name} FPI\", lw=1.5)\n",
    "            plt.title(\n",
    "                f\"{model_name} {member} {pretty_name} FPI \"\n",
    "                f\"(1900‚Äì2005)\\nTrend = {trend:.3f} {units}/century\"\n",
    "            )\n",
    "            plt.xlabel(\"Year\")\n",
    "            plt.ylabel(f\"FPI ({units})\")\n",
    "            plt.grid(alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / f\"{model_name}_{member}_FPI_{pretty_name}.png\", dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "            # save time series\n",
    "            fpi.to_netcdf(output_dir / f\"{model_name}_{member}_FPI_{pretty_name}.nc\")\n",
    "\n",
    "            print(f\"  ‚úì {pretty_name}: trend = {trend:.3f} {units}/century\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Skipping {pretty_name} for {member}: {e}\")\n",
    "\n",
    "# save summary\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows)\n",
    "    csv_path = output_dir / f\"FPI_trends_{model_name}.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n‚úÖ Saved trends table: {csv_path}\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"\\n‚ùå No FPI results were generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimoc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
